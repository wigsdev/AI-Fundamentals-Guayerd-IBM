"""
Script de Automatizaci√≥n - An√°lisis ML Tienda de Ropa Online
Proyecto: Fundamentos de IA - IBM SkillsBuild & Guayerd
Autor: Proyecto Sprint 3
Fecha: 2025-11-28

Este script automatiza todo el proceso de Machine Learning:
1. Carga y exploraci√≥n de datos
2. Preprocesamiento (encoding)
3. Divisi√≥n train/test
4. Entrenamiento de modelos (Clasificaci√≥n y Regresi√≥n)
5. Evaluaci√≥n con m√©tricas
6. Generaci√≥n de visualizaciones
7. Guardado de modelos
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error, r2_score
import pickle
import os
from datetime import datetime

# Configuraci√≥n de visualizaci√≥n
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

class MLPipeline:
    """Pipeline completo de Machine Learning para an√°lisis de tienda online"""
    
    def __init__(self, data_path):
        """
        Inicializa el pipeline
        
        Args:
            data_path (str): Ruta al archivo CSV con los datos
        """
        self.data_path = data_path
        self.df = None
        self.df_encoded = None
        self.X = None
        self.y_compra = None
        self.y_importe = None
        self.modelo_clasificacion = None
        self.modelo_regresion = None
        self.resultados = {}
        
        print("=" * 80)
        print("üöÄ PIPELINE DE MACHINE LEARNING - TIENDA DE ROPA ONLINE")
        print("=" * 80)
        print(f"Fecha de ejecuci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    def cargar_datos(self):
        """Paso 1: Carga y exploraci√≥n inicial de datos"""
        print("\n" + "=" * 80)
        print("üìä PASO 1: CARGA Y EXPLORACI√ìN DE DATOS")
        print("=" * 80)
        
        self.df = pd.read_csv(self.data_path)
        print(f"\n‚úÖ Dataset cargado exitosamente")
        print(f"   Dimensiones: {self.df.shape[0]} filas x {self.df.shape[1]} columnas")
        print(f"   Tasa de Conversi√≥n: {self.df['compra'].mean() * 100:.2f}%")
        print(f"   Importe Promedio (compras): ${self.df[self.df['compra']==1]['importe'].mean():.2f}")
        
        return self
    
    def preprocesar_datos(self):
        """Paso 2: Preprocesamiento - One-Hot Encoding"""
        print("\n" + "=" * 80)
        print("üîß PASO 2: PREPROCESAMIENTO DE DATOS")
        print("=" * 80)
        
        self.df_encoded = self.df.copy()
        self.df_encoded = pd.get_dummies(
            self.df_encoded, 
            columns=['fuente', 'dispositivo'], 
            drop_first=False
        )
        
        print(f"\n‚úÖ Variables categ√≥ricas codificadas")
        print(f"   Dimensiones: {self.df_encoded.shape[0]} filas x {self.df_encoded.shape[1]} columnas")
        print(f"   Nuevas columnas creadas: {self.df_encoded.shape[1] - self.df.shape[1]}")
        
        return self
    
    def dividir_datos(self):
        """Paso 3: Divisi√≥n train/test"""
        print("\n" + "=" * 80)
        print("‚úÇÔ∏è  PASO 3: DIVISI√ìN DE DATOS (TRAIN/TEST)")
        print("=" * 80)
        
        # Preparar features y targets
        self.X = self.df_encoded.drop(['compra', 'importe'], axis=1)
        self.y_compra = self.df_encoded['compra']
        self.y_importe = self.df_encoded['importe']
        
        # Divisi√≥n para clasificaci√≥n
        self.X_train_clf, self.X_test_clf, self.y_train_clf, self.y_test_clf = train_test_split(
            self.X, self.y_compra, test_size=0.3, random_state=42
        )
        
        # Divisi√≥n para regresi√≥n
        self.X_train_reg, self.X_test_reg, self.y_train_reg, self.y_test_reg = train_test_split(
            self.X, self.y_importe, test_size=0.3, random_state=42
        )
        
        print(f"\n‚úÖ Datos divididos:")
        print(f"   Train: {self.X_train_clf.shape[0]} registros (70%)")
        print(f"   Test: {self.X_test_clf.shape[0]} registros (30%)")
        
        return self
    
    def entrenar_clasificacion(self):
        """Paso 4: Entrenamiento del modelo de clasificaci√≥n"""
        print("\n" + "=" * 80)
        print("üéØ PASO 4: MODELO DE CLASIFICACI√ìN (Predicci√≥n de Compra)")
        print("=" * 80)
        
        # Entrenar modelo
        self.modelo_clasificacion = LogisticRegression(random_state=42, max_iter=1000)
        self.modelo_clasificacion.fit(self.X_train_clf, self.y_train_clf)
        
        # Predicciones
        y_pred_clf = self.modelo_clasificacion.predict(self.X_test_clf)
        
        # M√©tricas
        accuracy = accuracy_score(self.y_test_clf, y_pred_clf)
        matriz = confusion_matrix(self.y_test_clf, y_pred_clf)
        
        self.resultados['clasificacion'] = {
            'accuracy': accuracy,
            'matriz_confusion': matriz,
            'y_pred': y_pred_clf
        }
        
        print(f"\n‚úÖ Modelo entrenado exitosamente")
        print(f"   Algoritmo: Regresi√≥n Log√≠stica")
        print(f"   Accuracy: {accuracy:.2%}")
        print(f"\nüìä Matriz de Confusi√≥n:")
        print(f"   VN: {matriz[0,0]} | FP: {matriz[0,1]}")
        print(f"   FN: {matriz[1,0]} | VP: {matriz[1,1]}")
        
        return self
    
    def entrenar_regresion(self):
        """Paso 5: Entrenamiento del modelo de regresi√≥n"""
        print("\n" + "=" * 80)
        print("üí∞ PASO 5: MODELO DE REGRESI√ìN (Predicci√≥n de Importe)")
        print("=" * 80)
        
        # Entrenar modelo
        self.modelo_regresion = LinearRegression()
        self.modelo_regresion.fit(self.X_train_reg, self.y_train_reg)
        
        # Predicciones
        y_pred_reg = self.modelo_regresion.predict(self.X_test_reg)
        
        # M√©tricas
        mse = mean_squared_error(self.y_test_reg, y_pred_reg)
        rmse = np.sqrt(mse)
        r2 = r2_score(self.y_test_reg, y_pred_reg)
        
        self.resultados['regresion'] = {
            'mse': mse,
            'rmse': rmse,
            'r2': r2,
            'y_pred': y_pred_reg
        }
        
        print(f"\n‚úÖ Modelo entrenado exitosamente")
        print(f"   Algoritmo: Regresi√≥n Lineal")
        print(f"   R¬≤ Score: {r2:.4f}")
        print(f"   RMSE: ${rmse:.2f}")
        print(f"   Error Relativo: {(rmse/self.y_test_reg.mean())*100:.2f}%")
        
        return self
    
    def generar_visualizaciones(self, output_dir='../results'):
        """Paso 6: Generaci√≥n de visualizaciones"""
        print("\n" + "=" * 80)
        print("üìà PASO 6: GENERACI√ìN DE VISUALIZACIONES")
        print("=" * 80)
        
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. Matriz de Confusi√≥n
        plt.figure(figsize=(8, 6))
        sns.heatmap(
            self.resultados['clasificacion']['matriz_confusion'], 
            annot=True, fmt='d', cmap='Blues',
            square=True, linewidths=2
        )
        plt.title('Matriz de Confusi√≥n - Modelo de Clasificaci√≥n', fontsize=14, fontweight='bold')
        plt.ylabel('Valor Real', fontsize=12)
        plt.xlabel('Valor Predicho', fontsize=12)
        plt.savefig(f'{output_dir}/matriz_confusion.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("   ‚úÖ Guardado: matriz_confusion.png")
        
        # 2. Valores Reales vs Predichos (Regresi√≥n)
        plt.figure(figsize=(10, 6))
        plt.scatter(self.y_test_reg, self.resultados['regresion']['y_pred'], 
                   color='steelblue', s=100, alpha=0.7, edgecolor='black')
        min_val = min(self.y_test_reg.min(), self.resultados['regresion']['y_pred'].min())
        max_val = max(self.y_test_reg.max(), self.resultados['regresion']['y_pred'].max())
        plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Predicci√≥n Perfecta')
        plt.xlabel('Importe Real', fontsize=12)
        plt.ylabel('Importe Predicho', fontsize=12)
        plt.title('Valores Reales vs Predichos - Modelo de Regresi√≥n', fontsize=14, fontweight='bold')
        plt.legend()
        plt.grid(alpha=0.3)
        plt.savefig(f'{output_dir}/regresion_scatter.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("   ‚úÖ Guardado: regresion_scatter.png")
        
        return self
    
    def guardar_modelos(self, output_dir='models'):
        """Paso 7: Guardado de modelos entrenados"""
        print("\n" + "=" * 80)
        print("üíæ PASO 7: GUARDADO DE MODELOS")
        print("=" * 80)
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Guardar modelo de clasificaci√≥n
        with open(f'{output_dir}/modelo_clasificacion.pkl', 'wb') as f:
            pickle.dump(self.modelo_clasificacion, f)
        print("   ‚úÖ Guardado: modelo_clasificacion.pkl")
        
        # Guardar modelo de regresi√≥n
        with open(f'{output_dir}/modelo_regresion.pkl', 'wb') as f:
            pickle.dump(self.modelo_regresion, f)
        print("   ‚úÖ Guardado: modelo_regresion.pkl")
        
        return self
    
    def generar_reporte(self):
        """Genera un reporte final con todos los resultados"""
        print("\n" + "=" * 80)
        print("üìã REPORTE FINAL DE RESULTADOS")
        print("=" * 80)
        
        print("\nüéØ MODELO DE CLASIFICACI√ìN:")
        print(f"   Accuracy: {self.resultados['clasificacion']['accuracy']:.2%}")
        print(f"   Interpretaci√≥n: El modelo predice correctamente el {self.resultados['clasificacion']['accuracy']:.2%} de las compras")
        
        print("\nüí∞ MODELO DE REGRESI√ìN:")
        print(f"   R¬≤ Score: {self.resultados['regresion']['r2']:.4f}")
        print(f"   RMSE: ${self.resultados['regresion']['rmse']:.2f}")
        print(f"   Interpretaci√≥n: El modelo explica el {self.resultados['regresion']['r2']*100:.2f}% de la variabilidad")
        
        print("\nüìä INSIGHTS DE NEGOCIO:")
        print(f"   Tasa de Conversi√≥n: {self.df['compra'].mean()*100:.2f}%")
        print(f"   Importe Promedio: ${self.df[self.df['compra']==1]['importe'].mean():.2f}")
        print(f"   Tiempo Promedio en Sitio: {self.df['tiempo'].mean():.2f} minutos")
        
        print("\n" + "=" * 80)
        print("‚úÖ PIPELINE COMPLETADO EXITOSAMENTE")
        print("=" * 80)
        
        return self
    
    def ejecutar_pipeline_completo(self):
        """Ejecuta todo el pipeline de ML de principio a fin"""
        try:
            (self
             .cargar_datos()
             .preprocesar_datos()
             .dividir_datos()
             .entrenar_clasificacion()
             .entrenar_regresion()
             .generar_visualizaciones()
             .guardar_modelos()
             .generar_reporte())
            
            print("\nüéâ ¬°Pipeline ejecutado con √©xito!")
            return True
            
        except Exception as e:
            print(f"\n‚ùå Error durante la ejecuci√≥n: {str(e)}")
            import traceback
            traceback.print_exc()
            return False


def main():
    """Funci√≥n principal"""
    # Ruta al dataset
    data_path = '../data/datos_marketing.csv'
    
    # Crear y ejecutar pipeline
    pipeline = MLPipeline(data_path)
    exito = pipeline.ejecutar_pipeline_completo()
    
    if exito:
        print("\nüí° Los modelos y visualizaciones est√°n listos para usar!")
        print("   - Modelos guardados en: ../models/")
        print("   - Visualizaciones en: ../../results/")
    
    return 0 if exito else 1


if __name__ == "__main__":
    exit(main())
